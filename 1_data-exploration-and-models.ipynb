{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bicycle Sharing Demand Forcasting\n",
    "\n",
    "## Overview\n",
    "### I. Data Preprocessing and Feature Extraction\n",
    "- Add Weekday Column\n",
    "- Convert Categorical Variables\n",
    "- Check Missing Values\n",
    "- Extract Date and Time Features\n",
    "\n",
    "### II. Model Development\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Gradient-Boosted Tree Regression\n",
    "- Best Model\n",
    "\n",
    "### III. Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import calendar\n",
    "from pyspark.sql.functions import col, when, year, month, dayofmonth, hour, date_format\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Transformation and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+\n",
      "|            datetime|season|holiday|workingday|weather|temp| atemp|humidity|windspeed|casual|registered|count|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+\n",
      "|2011-01-01 00:00:...|     1|      0|         0|      1|9.84|14.395|      81|      0.0|     3|        13|   16|\n",
      "|2011-01-01 01:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     8|        32|   40|\n",
      "|2011-01-01 02:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     5|        27|   32|\n",
      "|2011-01-01 03:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     3|        10|   13|\n",
      "|2011-01-01 04:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     0|         1|    1|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read data in Spark\n",
    "df = spark.read.load('../project-bike-sharing-demand-forecast/data/train.csv',\n",
    "                     format='csv', inferSchema=True, header=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>season</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>2.506614</td>\n",
       "      <td>1.116174</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>holiday</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.166599</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workingday</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>0.680875</td>\n",
       "      <td>0.466159</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>1.418427</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temp</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>20.230860</td>\n",
       "      <td>7.791590</td>\n",
       "      <td>0.82</td>\n",
       "      <td>13.9400</td>\n",
       "      <td>20.500</td>\n",
       "      <td>26.2400</td>\n",
       "      <td>41.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atemp</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>23.655084</td>\n",
       "      <td>8.474601</td>\n",
       "      <td>0.76</td>\n",
       "      <td>16.6650</td>\n",
       "      <td>24.240</td>\n",
       "      <td>31.0600</td>\n",
       "      <td>45.4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humidity</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>61.886460</td>\n",
       "      <td>19.245033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>77.0000</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windspeed</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>12.799395</td>\n",
       "      <td>8.164537</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.0015</td>\n",
       "      <td>12.998</td>\n",
       "      <td>16.9979</td>\n",
       "      <td>56.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casual</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>36.021955</td>\n",
       "      <td>49.960477</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>49.0000</td>\n",
       "      <td>367.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>registered</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>155.552177</td>\n",
       "      <td>151.039033</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>118.000</td>\n",
       "      <td>222.0000</td>\n",
       "      <td>886.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10886.0</td>\n",
       "      <td>191.574132</td>\n",
       "      <td>181.144454</td>\n",
       "      <td>1.00</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>145.000</td>\n",
       "      <td>284.0000</td>\n",
       "      <td>977.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean         std   min      25%      50%       75%  \\\n",
       "season      10886.0    2.506614    1.116174  1.00   2.0000    3.000    4.0000   \n",
       "holiday     10886.0    0.028569    0.166599  0.00   0.0000    0.000    0.0000   \n",
       "workingday  10886.0    0.680875    0.466159  0.00   0.0000    1.000    1.0000   \n",
       "weather     10886.0    1.418427    0.633839  1.00   1.0000    1.000    2.0000   \n",
       "temp        10886.0   20.230860    7.791590  0.82  13.9400   20.500   26.2400   \n",
       "atemp       10886.0   23.655084    8.474601  0.76  16.6650   24.240   31.0600   \n",
       "humidity    10886.0   61.886460   19.245033  0.00  47.0000   62.000   77.0000   \n",
       "windspeed   10886.0   12.799395    8.164537  0.00   7.0015   12.998   16.9979   \n",
       "casual      10886.0   36.021955   49.960477  0.00   4.0000   17.000   49.0000   \n",
       "registered  10886.0  155.552177  151.039033  0.00  36.0000  118.000  222.0000   \n",
       "count       10886.0  191.574132  181.144454  1.00  42.0000  145.000  284.0000   \n",
       "\n",
       "                 max  \n",
       "season        4.0000  \n",
       "holiday       1.0000  \n",
       "workingday    1.0000  \n",
       "weather       4.0000  \n",
       "temp         41.0000  \n",
       "atemp        45.4550  \n",
       "humidity    100.0000  \n",
       "windspeed    56.9969  \n",
       "casual      367.0000  \n",
       "registered  886.0000  \n",
       "count       977.0000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary\n",
    "df.toPandas().describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weather: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data type\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Weekday Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|weekday|           datetime2|\n",
      "+-------+--------------------+\n",
      "|      6|2011-01-01 00:00:...|\n",
      "|      6|2011-01-01 01:00:...|\n",
      "|      6|2011-01-01 02:00:...|\n",
      "|      6|2011-01-01 03:00:...|\n",
      "|      6|2011-01-01 04:00:...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+\n",
      "|            datetime|season|holiday|workingday|weather|temp| atemp|humidity|windspeed|casual|registered|count|weekday|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+\n",
      "|2011-01-01 00:00:...|     1|      0|         0|      1|9.84|14.395|      81|      0.0|     3|        13|   16|      6|\n",
      "|2011-01-01 01:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     8|        32|   40|      6|\n",
      "|2011-01-01 02:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     5|        27|   32|      6|\n",
      "|2011-01-01 03:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     3|        10|   13|      6|\n",
      "|2011-01-01 04:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     0|         1|    1|      6|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_weekday = df.select('datetime', date_format('datetime', 'u').\\\n",
    "                        alias('weekday')).withColumn('datetime2', df.datetime).\\\n",
    "                        drop('datetime')\n",
    "df_weekday.show(5)\n",
    "df = df.join(df_weekday, df.datetime == df_weekday.datetime2).drop('datetime2')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10886"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weather: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Categorical Variables\n",
    "In spark 3.0, OneHotEncoder could transform several columns in one transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+\n",
      "|            datetime|season|holiday|workingday|weather|temp| atemp|humidity|windspeed|casual|registered|count|weekday|seasonIndex|seasonVec|holidayIndex|workingdayIndex|weatherIndex|   weatherVec|weekdayIndex|   weekdayVec|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+\n",
      "|2011-01-01 00:00:...|     1|      0|         0|      1|9.84|14.395|      81|      0.0|     3|        13|   16|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|\n",
      "|2011-01-01 01:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     8|        32|   40|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|\n",
      "|2011-01-01 02:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     5|        27|   32|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|\n",
      "|2011-01-01 03:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     3|        10|   13|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|\n",
      "|2011-01-01 04:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     0|         1|    1|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seasonIndexer = StringIndexer(inputCol='season', outputCol='seasonIndex')\n",
    "seasonEncoder = OneHotEncoder(inputCol='seasonIndex', outputCol='seasonVec')\n",
    "\n",
    "holidayIndexer = StringIndexer(inputCol='holiday', outputCol='holidayIndex')\n",
    "\n",
    "workingdayIndexer = StringIndexer(inputCol='workingday', outputCol='workingdayIndex')\n",
    "\n",
    "weatherIndexer = StringIndexer(inputCol='weather', outputCol='weatherIndex')\n",
    "weatherEncoder = OneHotEncoder(inputCol='weatherIndex', outputCol='weatherVec')\n",
    "\n",
    "weekdayIndexer = StringIndexer(inputCol='weekday', outputCol='weekdayIndex')\n",
    "weekdayEncoder = OneHotEncoder(inputCol='weekdayIndex', outputCol='weekdayVec')\n",
    "\n",
    "pipeline = Pipeline(stages=[seasonIndexer, seasonEncoder, \n",
    "                            holidayIndexer, workingdayIndexer, \n",
    "                            weatherIndexer, weatherEncoder, \n",
    "                            weekdayIndexer, weekdayEncoder])\n",
    "preprocess = pipeline.fit(df)\n",
    "df_transformed = preprocess.transform(df)\n",
    "df_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- season: integer (nullable = true)\n",
      " |-- holiday: integer (nullable = true)\n",
      " |-- workingday: integer (nullable = true)\n",
      " |-- weather: integer (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- atemp: double (nullable = true)\n",
      " |-- humidity: integer (nullable = true)\n",
      " |-- windspeed: double (nullable = true)\n",
      " |-- casual: integer (nullable = true)\n",
      " |-- registered: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- weekday: string (nullable = true)\n",
      " |-- seasonIndex: double (nullable = true)\n",
      " |-- seasonVec: vector (nullable = true)\n",
      " |-- holidayIndex: double (nullable = true)\n",
      " |-- workingdayIndex: double (nullable = true)\n",
      " |-- weatherIndex: double (nullable = true)\n",
      " |-- weatherVec: vector (nullable = true)\n",
      " |-- weekdayIndex: double (nullable = true)\n",
      " |-- weekdayVec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime           0\n",
       "season             0\n",
       "holiday            0\n",
       "workingday         0\n",
       "weather            0\n",
       "temp               0\n",
       "atemp              0\n",
       "humidity           0\n",
       "windspeed          0\n",
       "casual             0\n",
       "registered         0\n",
       "count              0\n",
       "weekday            0\n",
       "seasonIndex        0\n",
       "seasonVec          0\n",
       "holidayIndex       0\n",
       "workingdayIndex    0\n",
       "weatherIndex       0\n",
       "weatherVec         0\n",
       "weekdayIndex       0\n",
       "weekdayVec         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Date and Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+----+-----+---+----+\n",
      "|            datetime|season|holiday|workingday|weather|temp| atemp|humidity|windspeed|casual|registered|count|weekday|seasonIndex|seasonVec|holidayIndex|workingdayIndex|weatherIndex|   weatherVec|weekdayIndex|   weekdayVec|year|month|day|hour|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+----+-----+---+----+\n",
      "|2011-01-01 00:00:...|     1|      0|         0|      1|9.84|14.395|      81|      0.0|     3|        13|   16|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|2011|    1|  1|   0|\n",
      "|2011-01-01 01:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     8|        32|   40|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|2011|    1|  1|   1|\n",
      "|2011-01-01 02:00:...|     1|      0|         0|      1|9.02|13.635|      80|      0.0|     5|        27|   32|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|2011|    1|  1|   2|\n",
      "|2011-01-01 03:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     3|        10|   13|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|2011|    1|  1|   3|\n",
      "|2011-01-01 04:00:...|     1|      0|         0|      1|9.84|14.395|      75|      0.0|     0|         1|    1|      6|        3.0|(3,[],[])|         0.0|            1.0|         0.0|(3,[0],[1.0])|         0.0|(6,[0],[1.0])|2011|    1|  1|   4|\n",
      "+--------------------+------+-------+----------+-------+----+------+--------+---------+------+----------+-----+-------+-----------+---------+------------+---------------+------------+-------------+------------+-------------+----+-----+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed = df_transformed.withColumn('year', year(df_transformed.datetime))\n",
    "df_transformed = df_transformed.withColumn('month', month(df_transformed.datetime))\n",
    "df_transformed = df_transformed.withColumn('day', dayofmonth(df_transformed.datetime))\n",
    "df_transformed = df_transformed.withColumn('hour', hour(df_transformed.datetime))\n",
    "df_transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|count|\n",
      "+-----+-----+\n",
      "|    1|  884|\n",
      "|    2|  901|\n",
      "|    3|  901|\n",
      "|    4|  909|\n",
      "|    5|  912|\n",
      "|    6|  912|\n",
      "|    7|  912|\n",
      "|    8|  912|\n",
      "|    9|  909|\n",
      "|   10|  911|\n",
      "|   11|  911|\n",
      "|   12|  912|\n",
      "+-----+-----+\n",
      "\n",
      "+----+-----+\n",
      "|hour|count|\n",
      "+----+-----+\n",
      "|   0|  455|\n",
      "|   1|  454|\n",
      "|   2|  448|\n",
      "|   3|  433|\n",
      "|   4|  442|\n",
      "|   5|  452|\n",
      "|   6|  455|\n",
      "|   7|  455|\n",
      "|   8|  455|\n",
      "|   9|  455|\n",
      "|  10|  455|\n",
      "|  11|  455|\n",
      "|  12|  456|\n",
      "|  13|  456|\n",
      "|  14|  456|\n",
      "|  15|  456|\n",
      "|  16|  456|\n",
      "|  17|  456|\n",
      "|  18|  456|\n",
      "|  19|  456|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counts by month and hour\n",
    "df_transformed.groupBy('month').count().orderBy('month').show()\n",
    "df_transformed.groupBy('hour').count().orderBy('hour').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['datetime',\n",
       " 'season',\n",
       " 'holiday',\n",
       " 'workingday',\n",
       " 'weather',\n",
       " 'temp',\n",
       " 'atemp',\n",
       " 'humidity',\n",
       " 'windspeed',\n",
       " 'casual',\n",
       " 'registered',\n",
       " 'count',\n",
       " 'weekday',\n",
       " 'seasonIndex',\n",
       " 'seasonVec',\n",
       " 'holidayIndex',\n",
       " 'workingdayIndex',\n",
       " 'weatherIndex',\n",
       " 'weatherVec',\n",
       " 'weekdayIndex',\n",
       " 'weekdayVec',\n",
       " 'year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|count|\n",
      "+--------------------+-----+\n",
      "|(22,[0,1,2,3,4,5,...|   51|\n",
      "|(22,[0,1,2,3,4,5,...|   15|\n",
      "|(22,[0,1,2,3,4,5,...|   37|\n",
      "|(22,[0,1,2,3,4,5,...|   59|\n",
      "|(22,[0,1,2,3,4,5,...|   10|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and train_test\n",
    "vectorAssembler = VectorAssembler(inputCols = ['temp', 'atemp', 'humidity', 'windspeed',\n",
    "                                               'holidayIndex', 'workingdayIndex', \n",
    "                                               'seasonVec', 'weatherVec', 'weekdayVec',\n",
    "                                               'year', 'month', 'day', 'hour'],\n",
    "                                  outputCol = 'features')\n",
    "\n",
    "df_v = vectorAssembler.transform(df_transformed).select(['features', 'count'])\n",
    "trainingData, testData = df_v.randomSplit([0.7, 0.3], seed=123)\n",
    "trainingData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(features=SparseVector(22, {0: 15.58, 1: 19.695, 2: 76.0, 3: 19.0012, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 15: 1.0, 18: 2012.0, 19: 10.0, 20: 8.0})),\n",
       " Row(features=SparseVector(22, {0: 13.94, 1: 16.665, 2: 81.0, 3: 12.998, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 15: 1.0, 18: 2012.0, 19: 10.0, 20: 8.0, 21: 2.0})),\n",
       " Row(features=SparseVector(22, {0: 13.94, 1: 16.665, 2: 87.0, 3: 11.0014, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 15: 1.0, 18: 2012.0, 19: 10.0, 20: 8.0, 21: 1.0})),\n",
       " Row(features=SparseVector(22, {0: 13.94, 1: 17.425, 2: 76.0, 3: 7.0015, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 15: 1.0, 18: 2012.0, 19: 10.0, 20: 8.0, 21: 6.0})),\n",
       " Row(features=SparseVector(22, {0: 13.94, 1: 17.425, 2: 81.0, 3: 7.0015, 4: 1.0, 5: 1.0, 6: 1.0, 9: 1.0, 15: 1.0, 18: 2012.0, 19: 10.0, 20: 8.0, 21: 3.0}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.select('features').collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on training data: 0.396315\n",
      "RMSE on training data: 140.887702\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(featuresCol='features', labelCol='count', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "model = lr.fit(trainingData)\n",
    "\n",
    "trainingSummary = model.summary\n",
    "print(\"R2 on training data: %f\" % trainingSummary.r2)\n",
    "print(\"RMSE on training data: %f\" % trainingSummary.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|138.49513314547949|   49|(22,[0,1,2,3,4,5,...|\n",
      "|101.19490156535176|    7|(22,[0,1,2,3,4,5,...|\n",
      "|134.53935378280585|   19|(22,[0,1,2,3,4,5,...|\n",
      "|141.26062935087248|   71|(22,[0,1,2,3,4,5,...|\n",
      "|139.45178153016604|   20|(22,[0,1,2,3,4,5,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R2 on test data = 0.399798\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "lr_evaluator = RegressionEvaluator(predictionCol = 'prediction', labelCol = 'count', metricName = 'r2')\n",
    "print('R2 on test data = %g' % lr_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 139.947\n"
     ]
    }
   ],
   "source": [
    "lr_evaluator = RegressionEvaluator(predictionCol = 'prediction', labelCol = 'count', metricName = 'rmse')\n",
    "print('RMSE on test data = %g' % lr_evaluator.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 139.947\n"
     ]
    }
   ],
   "source": [
    "# Another way to get RMSE\n",
    "test_result = model.evaluate(testData)\n",
    "print(\"RMSE: %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "| 38.01774180400779|   49|(22,[0,1,2,3,4,5,...|\n",
      "|31.319701589655875|    7|(22,[0,1,2,3,4,5,...|\n",
      "|31.319701589655875|   19|(22,[0,1,2,3,4,5,...|\n",
      "|50.693602259880905|   71|(22,[0,1,2,3,4,5,...|\n",
      "|29.823022653806664|   20|(22,[0,1,2,3,4,5,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R2 on test data = 0.627869\n",
      "RMSE on test data = 110.195\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(featuresCol='features', labelCol = 'count')\n",
    "model = rf.fit(trainingData)\n",
    "# trainingSummary = model.summary\n",
    "# print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "# print(\"r2: %f\" % trainingSummary.r2)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"count\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 on test data = %g\" % r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+--------------------+\n",
      "|        prediction|count|            features|\n",
      "+------------------+-----+--------------------+\n",
      "|150.92764873664677|   49|(22,[0,1,2,3,4,5,...|\n",
      "| 4.409337127145523|    7|(22,[0,1,2,3,4,5,...|\n",
      "| 16.66925700791984|   19|(22,[0,1,2,3,4,5,...|\n",
      "| 41.57749804093572|   71|(22,[0,1,2,3,4,5,...|\n",
      "|44.750680504485594|   20|(22,[0,1,2,3,4,5,...|\n",
      "+------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R2 on test data = 0.940077\n",
      "RMSE on test data = 44.2192\n",
      "Wall time: 3min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol = 'count', maxIter=100)\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"prediction\", \"count\", \"features\").show(5)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"count\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 on test data = %g\" % r2)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"count\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model\n",
    "It seems gradient-boosted tree regression could generate much better prediction than linear regression or random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Predict New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-------+----------+-------+-----+------+--------+---------+-------+\n",
      "|            datetime|season|holiday|workingday|weather| temp| atemp|humidity|windspeed|weekday|\n",
      "+--------------------+------+-------+----------+-------+-----+------+--------+---------+-------+\n",
      "|2011-01-20 00:00:...|     1|      0|         1|      1|10.66|11.365|      56|  26.0027|      4|\n",
      "|2011-01-20 01:00:...|     1|      0|         1|      1|10.66|13.635|      56|      0.0|      4|\n",
      "|2011-01-20 02:00:...|     1|      0|         1|      1|10.66|13.635|      56|      0.0|      4|\n",
      "|2011-01-20 03:00:...|     1|      0|         1|      1|10.66| 12.88|      56|  11.0014|      4|\n",
      "|2011-01-20 04:00:...|     1|      0|         1|      1|10.66| 12.88|      56|  11.0014|      4|\n",
      "+--------------------+------+-------+----------+-------+-----+------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|            datetime|            features|\n",
      "+--------------------+--------------------+\n",
      "|2011-01-20 00:00:...|(22,[0,1,2,3,9,14...|\n",
      "|2011-01-20 01:00:...|(22,[0,1,2,9,14,1...|\n",
      "|2011-01-20 02:00:...|(22,[0,1,2,9,14,1...|\n",
      "|2011-01-20 03:00:...|(22,[0,1,2,3,9,14...|\n",
      "|2011-01-20 04:00:...|(22,[0,1,2,3,9,14...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_submit = spark.read.load('../project-bike-sharing-demand-forecast/data/test.csv',\n",
    "                            format='csv', inferSchema=True, header=True)\n",
    "\n",
    "df_weekday = df_submit.select('datetime', date_format('datetime', 'u').\\\n",
    "                              alias('weekday')).withColumn('datetime2', df_submit.datetime).\\\n",
    "                              drop('datetime')\n",
    "df_submit = df_submit.join(df_weekday, df_submit.datetime == df_weekday.datetime2).drop('datetime2')\n",
    "df_submit.show(5)\n",
    "\n",
    "df_submit = preprocess.transform(df_submit)\n",
    "\n",
    "df_submit = df_submit.withColumn('year', year(df_submit.datetime))\n",
    "df_submit = df_submit.withColumn('month', month(df_submit.datetime))\n",
    "df_submit = df_submit.withColumn('day', dayofmonth(df_submit.datetime))\n",
    "df_submit = df_submit.withColumn('hour', hour(df_submit.datetime))\n",
    "\n",
    "df_submit = vectorAssembler.transform(df_submit).select(['datetime', 'features'])\n",
    "df_submit.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6493"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol = 'count', maxIter=100)\n",
    "model = gbt.fit(df_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+\n",
      "|            datetime|        prediction|            features|\n",
      "+--------------------+------------------+--------------------+\n",
      "|2011-01-20 00:00:...|19.780597824939615|(22,[0,1,2,3,9,14...|\n",
      "|2011-01-20 01:00:...|-5.383336840951198|(22,[0,1,2,9,14,1...|\n",
      "|2011-01-20 02:00:...|-10.46068656792588|(22,[0,1,2,9,14,1...|\n",
      "|2011-01-20 03:00:...|-7.311465358099026|(22,[0,1,2,3,9,14...|\n",
      "|2011-01-20 04:00:...|-7.005824313567958|(22,[0,1,2,3,9,14...|\n",
      "+--------------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df_submit)\n",
    "predictions.select('datetime', 'prediction', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------+------------------+\n",
      "|            datetime|            features|        prediction|             count|\n",
      "+--------------------+--------------------+------------------+------------------+\n",
      "|2011-01-20 00:00:...|(22,[0,1,2,3,9,14...|19.780597824939615|19.780597824939615|\n",
      "|2011-01-20 01:00:...|(22,[0,1,2,9,14,1...|-5.383336840951198|               0.0|\n",
      "|2011-01-20 02:00:...|(22,[0,1,2,9,14,1...|-10.46068656792588|               0.0|\n",
      "|2011-01-20 03:00:...|(22,[0,1,2,3,9,14...|-7.311465358099026|               0.0|\n",
      "|2011-01-20 04:00:...|(22,[0,1,2,3,9,14...|-7.005824313567958|               0.0|\n",
      "+--------------------+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_prediction = predictions.withColumn('count', when(predictions.prediction < 0, 0).otherwise(predictions.prediction))\n",
    "new_prediction.show(5)\n",
    "new_prediction.select(['datetime', 'count']).toPandas().to_csv('../project-bike-sharing-demand-forecast/data/submission.csv', index=False)\n",
    "# 0.72496 Rank 2559"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's still room to develop my best model, and more works for prediction improvements will be done in the future. Below is an overview of the current progress."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
